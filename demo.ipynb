{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697a1b64-a9f0-4b9b-b6dc-164a2fabd2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip install nvcc4jupyter\n",
      "\n",
      "\n",
      "%load_ext nvcc4jupyter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "%%cuda\n",
      "#include <stdio.h>\n",
      "#include <iostream>\n",
      "\n",
      "using namespace std;\n",
      "\n",
      "// CUDA code to multiply matrices\n",
      "__global__ void multiply(int* A, int* B, int* C, int size) {\n",
      "    // Uses thread idices and block indices to compute each element\n",
      "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
      "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
      "\n",
      "    if (row < size && col < size) {\n",
      "        int sum = 0;\n",
      "        for (int i = 0; i < size; i++) {\n",
      "            sum += A[row * size + i] * B[i * size + col];\n",
      "        }\n",
      "        C[row * size + col] = sum;\n",
      "    }\n",
      "}\n",
      "\n",
      "void initialize(int* matrix, int size) {\n",
      "    for (int i = 0; i < size * size; i++) {\n",
      "        matrix[i] = rand() % 10;\n",
      "    }\n",
      "}\n",
      "\n",
      "void print(int* matrix, int size) {\n",
      "    for (int row = 0; row < size; row++) {\n",
      "        for (int col = 0; col < size; col++) {\n",
      "            cout << matrix[row * size + col] << \" \";\n",
      "        }\n",
      "        cout << '\\n';\n",
      "    }\n",
      "    cout << '\\n';\n",
      "}\n",
      "\n",
      "int main() {\n",
      "    int* A, * B, * C;\n",
      "\n",
      "    int N = 2;\n",
      "    int blockSize = 16;\n",
      "\n",
      "    int matrixSize = N * N;\n",
      "    size_t matrixBytes = matrixSize * sizeof(int);\n",
      "\n",
      "    A = new int[matrixSize];\n",
      "    B = new int[matrixSize];\n",
      "    C = new int[matrixSize];\n",
      "\n",
      "    initialize(A, N);\n",
      "    initialize(B, N);\n",
      "    cout << \"Matrix A: \\n\";\n",
      "    print(A, N);\n",
      "\n",
      "    cout << \"Matrix B: \\n\";\n",
      "    print(B, N);\n",
      "\n",
      "    int* X, * Y, * Z;\n",
      "    // Allocate space\n",
      "    cudaMalloc(&X, matrixBytes);\n",
      "    cudaMalloc(&Y, matrixBytes);\n",
      "    cudaMalloc(&Z, matrixBytes);\n",
      "\n",
      "    // Initialize matrix C to zero\n",
      "    cudaMemset(Z, 0, matrixBytes);\n",
      "\n",
      "    // Copy values from A to X\n",
      "    cudaMemcpy(X, A, matrixBytes, cudaMemcpyHostToDevice);\n",
      "\n",
      "    // Copy values from A to X and B to Y\n",
      "    cudaMemcpy(Y, B, matrixBytes, cudaMemcpyHostToDevice);\n",
      "\n",
      "    // Threads per CTA dimension\n",
      "    int THREADS = 2;\n",
      "\n",
      "    // Blocks per grid dimension\n",
      "    int BLOCKS = (N + THREADS - 1) / THREADS;\n",
      "\n",
      "    // Use dim3 structs for block and grid dimensions\n",
      "    dim3 threads(THREADS, THREADS);\n",
      "    dim3 blocks(BLOCKS, BLOCKS);\n",
      "\n",
      "    // Launch kernel\n",
      "    multiply<<<blocks, threads>>>(X, Y, Z, N);\n",
      "\n",
      "    cudaMemcpy(C, Z, matrixBytes, cudaMemcpyDeviceToHost);\n",
      "    cout << \"Multiplication of matrix A and B: \\n\";\n",
      "    print(C, N);\n",
      "\n",
      "    delete[] A;\n",
      "    delete[] B;\n",
      "    delete[] C;\n",
      "\n",
      "    cudaFree(X);\n",
      "    cudaFree(Y);\n",
      "    cudaFree(Z);\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "print(requests.get(\"https://raw.githubusercontent.com/Hardikmaind/prac8/main/hpc/mm.txt\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aed7c5-dc95-413f-90f6-904dad4a40fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nvcc4jupyter\n",
    "\n",
    "\n",
    "%load_ext nvcc4jupyter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%%cuda\n",
    "#include <stdio.h>\n",
    "#include <iostream>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "// CUDA code to multiply matrices\n",
    "__global__ void multiply(int* A, int* B, int* C, int size) {\n",
    "    // Uses thread idices and block indices to compute each element\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (row < size && col < size) {\n",
    "        int sum = 0;\n",
    "        for (int i = 0; i < size; i++) {\n",
    "            sum += A[row * size + i] * B[i * size + col];\n",
    "        }\n",
    "        C[row * size + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "void initialize(int* matrix, int size) {\n",
    "    for (int i = 0; i < size * size; i++) {\n",
    "        matrix[i] = rand() % 10;\n",
    "    }\n",
    "}\n",
    "\n",
    "void print(int* matrix, int size) {\n",
    "    for (int row = 0; row < size; row++) {\n",
    "        for (int col = 0; col < size; col++) {\n",
    "            cout << matrix[row * size + col] << \" \";\n",
    "        }\n",
    "        cout << '\\n';\n",
    "    }\n",
    "    cout << '\\n';\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int* A, * B, * C;\n",
    "\n",
    "    int N = 2;\n",
    "    int blockSize = 16;\n",
    "\n",
    "    int matrixSize = N * N;\n",
    "    size_t matrixBytes = matrixSize * sizeof(int);\n",
    "\n",
    "    A = new int[matrixSize];\n",
    "    B = new int[matrixSize];\n",
    "    C = new int[matrixSize];\n",
    "\n",
    "    initialize(A, N);\n",
    "    initialize(B, N);\n",
    "    cout << \"Matrix A: \\n\";\n",
    "    print(A, N);\n",
    "\n",
    "    cout << \"Matrix B: \\n\";\n",
    "    print(B, N);\n",
    "\n",
    "    int* X, * Y, * Z;\n",
    "    // Allocate space\n",
    "    cudaMalloc(&X, matrixBytes);\n",
    "    cudaMalloc(&Y, matrixBytes);\n",
    "    cudaMalloc(&Z, matrixBytes);\n",
    "\n",
    "    // Initialize matrix C to zero\n",
    "    cudaMemset(Z, 0, matrixBytes);\n",
    "\n",
    "    // Copy values from A to X\n",
    "    cudaMemcpy(X, A, matrixBytes, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Copy values from A to X and B to Y\n",
    "    cudaMemcpy(Y, B, matrixBytes, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Threads per CTA dimension\n",
    "    int THREADS = 2;\n",
    "\n",
    "    // Blocks per grid dimension\n",
    "    int BLOCKS = (N + THREADS - 1) / THREADS;\n",
    "\n",
    "    // Use dim3 structs for block and grid dimensions\n",
    "    dim3 threads(THREADS, THREADS);\n",
    "    dim3 blocks(BLOCKS, BLOCKS);\n",
    "\n",
    "    // Launch kernel\n",
    "    multiply<<<blocks, threads>>>(X, Y, Z, N);\n",
    "\n",
    "    cudaMemcpy(C, Z, matrixBytes, cudaMemcpyDeviceToHost);\n",
    "    cout << \"Multiplication of matrix A and B: \\n\";\n",
    "    print(C, N);\n",
    "\n",
    "    delete[] A;\n",
    "    delete[] B;\n",
    "    delete[] C;\n",
    "\n",
    "    cudaFree(X);\n",
    "    cudaFree(Y);\n",
    "    cudaFree(Z);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
