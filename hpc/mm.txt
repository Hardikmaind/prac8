!pip install nvcc4jupyter


%load_ext nvcc4jupyter








%%cuda
#include <stdio.h>
#include <iostream>

using namespace std;

// CUDA code to multiply matrices
__global__ void multiply(int* A, int* B, int* C, int size) {
    // Uses thread idices and block indices to compute each element
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    if (row < size && col < size) {
        int sum = 0;
        for (int i = 0; i < size; i++) {
            sum += A[row * size + i] * B[i * size + col];
        }
        C[row * size + col] = sum;
    }
}

void initialize(int* matrix, int size) {
    for (int i = 0; i < size * size; i++) {
        matrix[i] = rand() % 10;
    }
}

void print(int* matrix, int size) {
    for (int row = 0; row < size; row++) {
        for (int col = 0; col < size; col++) {
            cout << matrix[row * size + col] << " ";
        }
        cout << '\n';
    }
    cout << '\n';
}

int main() {
    int* A, * B, * C;

    int N = 2;
    int blockSize = 16;

    int matrixSize = N * N;
    size_t matrixBytes = matrixSize * sizeof(int);

    A = new int[matrixSize];
    B = new int[matrixSize];
    C = new int[matrixSize];

    initialize(A, N);
    initialize(B, N);
    cout << "Matrix A: \n";
    print(A, N);

    cout << "Matrix B: \n";
    print(B, N);

    int* X, * Y, * Z;
    // Allocate space
    cudaMalloc(&X, matrixBytes);
    cudaMalloc(&Y, matrixBytes);
    cudaMalloc(&Z, matrixBytes);

    // Initialize matrix C to zero
    cudaMemset(Z, 0, matrixBytes);

    // Copy values from A to X
    cudaMemcpy(X, A, matrixBytes, cudaMemcpyHostToDevice);

    // Copy values from A to X and B to Y
    cudaMemcpy(Y, B, matrixBytes, cudaMemcpyHostToDevice);

    // Threads per CTA dimension
    int THREADS = 2;

    // Blocks per grid dimension
    int BLOCKS = (N + THREADS - 1) / THREADS;

    // Use dim3 structs for block and grid dimensions
    dim3 threads(THREADS, THREADS);
    dim3 blocks(BLOCKS, BLOCKS);

    // Launch kernel
    multiply<<<blocks, threads>>>(X, Y, Z, N);

    cudaMemcpy(C, Z, matrixBytes, cudaMemcpyDeviceToHost);
    cout << "Multiplication of matrix A and B: \n";
    print(C, N);

    delete[] A;
    delete[] B;
    delete[] C;

    cudaFree(X);
    cudaFree(Y);
    cudaFree(Z);

    return 0;
}



























































%%cuda
#include <iostream>
using namespace std;

const int N = 3; // Size of square matrices

// CUDA kernel to multiply matrices
__global__ void mul(int* A, int* B, int* C, int size) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    if (row < size && col < size) {
        int sum = 0;
        for (int i = 0; i < size; i++) {
            sum += A[row * size + i] * B[i * size + col];
        }
        C[row * size + col] = sum;
    }
}

int main() {
    int *h_A, *h_B, *h_C; // Host matrices

    // Allocate memory and initialize host matrices
    cudaMallocManaged(&h_A, N * N * sizeof(int));
    cudaMallocManaged(&h_B, N * N * sizeof(int));
    cudaMallocManaged(&h_C, N * N * sizeof(int));

    // Initialize host matrices
    for (int i = 0; i < N * N; i++) {
        h_A[i] = i;
        h_B[i] = 2 * i;
    }

    // Define grid and block dimensions
    dim3 dimGrid(1, 1, 1);
    dim3 dimBlock(N, N, 1);

    // Launch kernel
    mul<<<dimGrid, dimBlock>>>(h_A, h_B, h_C, N);
    cudaDeviceSynchronize();




     cout << " matrix A:" << endl;
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            cout << h_A[i * N + j] << " ";
        }
        cout << endl;
    }



     cout << " matrix B:" << endl;
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            cout << h_B[i * N + j] << " ";
        }
        cout << endl;
    }




    // Print result
    cout << "Result matrix:" << endl;
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            cout << h_C[i * N + j] << " ";
        }
        cout << endl;
    }

    // Free memory
    cudaFree(h_A);
    cudaFree(h_B);
    cudaFree(h_C);

    return 0;
}
