!pip install nvcc4jupyter


%load_ext nvcc4jupyter






%%cuda
#include <iostream>
#include <cuda_runtime.h>

using namespace std;

__global__
void add(int* A, int* B, int* C, int size) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;

    if (tid < size) {
        C[tid] = A[tid] + B[tid];
    }
}

void initialize(int* vector, int size, int values[]) {
    for (int i = 0; i < size; i++) {
        vector[i] = values[i];
    }
}

void print(int* vector, int size) {
    for (int i = 0; i < size; i++) {
        cout << vector[i] << " ";
    }
    cout << endl;
}

int main() {
    int N = 4;
    int* A, * B, * C;

    int vectorSize = N;
    size_t vectorBytes = vectorSize * sizeof(int);

    A = new int[vectorSize];
    B = new int[vectorSize];
    C = new int[vectorSize];

    int valuesA[] = {3, 6, 7, 5};
    int valuesB[] = {3, 5, 6, 2};

    initialize(A, vectorSize, valuesA);
    initialize(B, vectorSize, valuesB);

    cout << "Vector A: ";
    print(A, N);
    cout << "Vector B: ";
    print(B, N);

    int* X, * Y, * Z;
    cudaMalloc(&X, vectorBytes);
    cudaMalloc(&Y, vectorBytes);
    cudaMalloc(&Z, vectorBytes);

    cudaMemcpy(X, A, vectorBytes, cudaMemcpyHostToDevice);
    cudaMemcpy(Y, B, vectorBytes, cudaMemcpyHostToDevice);

    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;

    add<<<blocksPerGrid, threadsPerBlock>>>(X, Y, Z, N);

    cudaError_t cudaError = cudaGetLastError();
    if (cudaError != cudaSuccess) {
        cout << "CUDA Error: " << cudaGetErrorString(cudaError) << endl;
        return 1;
    }

    cudaMemcpy(C, Z, vectorBytes, cudaMemcpyDeviceToHost);

    cout << "Addition: ";
    print(C, N);

    for (int i = 0; i < 4; i++) {
        printf("%d + %d = %d\n", A[i], B[i], C[i]);
    }

    delete[] A;
    delete[] B;
    delete[] C;

    cudaFree(X);
    cudaFree(Y);
    cudaFree(Z);

    return 0;
}












































%%cuda
#include <iostream>

using namespace std;

__global__ void add(int* A, int* B, int* C, int size) {
    int i = threadIdx.x + blockIdx.x * blockDim.x;
    if (i < size) {
        C[i] = A[i] + B[i];
    }
}

int main() {
    const int N = 256;
    int *arra, *arrb, *arrc;

    cudaMallocManaged(&arra, N * sizeof(int));
    cudaMallocManaged(&arrb, N * sizeof(int));
    cudaMallocManaged(&arrc, N * sizeof(int));

    // Initialize arrays
    for (int i = 0; i < N; i++) {
        arra[i] = i;
        arrb[i] = 256 - i;
    }

    add << <1, 256 >> > (arra, arrb, arrc, N);
    cudaDeviceSynchronize();


    cout << " vector A:" << endl;
    for (int i = 0; i < N; i++) {
        cout << arra[i] << " ";
    }
    cout << endl;


    cout << " vector B:" << endl;
    for (int i = 0; i < N; i++) {
        cout << arrb[i] << " ";
    }
    cout << endl;

    cout << "Added vector:" << endl;
    for (int i = 0; i < N; i++) {
        cout << arrc[i] << " ";
    }
    cout << endl;

    cudaFree(arra);
    cudaFree(arrb);
    cudaFree(arrc);

    return 0;
}

